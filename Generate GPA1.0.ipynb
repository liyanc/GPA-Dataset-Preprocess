{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import cv2, lmdb, os\n",
    "import numpy as np\n",
    "import msgpack\n",
    "import msgpack_numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "msgpack_numpy.patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FileIO as fio\n",
    "import Execution as exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorpack import *\n",
    "from tensorpack.utils.utils import get_tqdm\n",
    "from tensorpack.utils import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaReader:\n",
    "    def __init__(self, path):\n",
    "        self.db = lmdb.open(path, subdir=False, map_size=1099511627776 * 2, readonly=True,\n",
    "                            meminit=False, map_async=True)\n",
    "        \n",
    "    def get(self, imgid):\n",
    "        k = u'{:0>10}'.format(imgid).encode('ascii')\n",
    "        with self.db.begin() as txn:\n",
    "            with txn.cursor() as cur:\n",
    "                return msgpack.loads(cur.get(k))\n",
    "            \n",
    "    def __iter__(self):\n",
    "        with self.db.begin() as txn:\n",
    "            with txn.cursor() as cur:\n",
    "                for k, v in cur:\n",
    "                    yield k, msgpack.loads(v)\n",
    "    \n",
    "    def close(self):\n",
    "        self.db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = \"/media/GPAmaster/GPA_master/new_meta.mdb\"\n",
    "meta_io = MetaReader(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_path = \"/media/GPAmaster/GPA_master\"\n",
    "dst_path_l = [\"/media/theta_scratch2/GPA1.0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d_path in dst_path_l:\n",
    "    exe.run_command([\"mkdir\", \"{:}/img\".format(d_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgf_gen():\n",
    "    for k, v in meta_io:\n",
    "        imgid, subj, takename, cam, src_file, dst_file, cam_ts, mocap_ts, sess_date, cam_param_f, markers, joints, geo_name, is_gpa1, is_test = v\n",
    "        if is_gpa1:\n",
    "            from_file = \"{:}/{:}\".format(rt_path, dst_file.decode())\n",
    "            with open(from_file, \"rb\") as in_f:\n",
    "                in_bytes = in_f.read()\n",
    "            for d_path in dst_path_l:\n",
    "                to_file = \"{:}/img/{:}\".format(d_path, os.path.basename(from_file))\n",
    "                yield in_bytes, to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copier(dp):\n",
    "    in_bytes, to_f = dp\n",
    "    with open(to_f, \"wb\") as out_f:\n",
    "        out_f.write(in_bytes)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = dataflow.DataFromGenerator(imgf_gen())\n",
    "mapped_df = dataflow.MultiProcessMapDataZMQ(in_df, 5, copier, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1107 20:49:42 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Install python-prctl so that processes can be cleaned with guarantee.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "323797it [2:09:22, 45.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1107 22:59:05 @parallel_map.py:53]\u001b[0m \u001b[4m\u001b[5m\u001b[31mERR\u001b[0m [MultiProcessMapDataZMQ] buffer_size cannot be larger than the size of the DataFlow!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "324009it [2:09:59, 10.11it/s]\n"
     ]
    }
   ],
   "source": [
    "with get_tqdm(total=0) as pbar:\n",
    "    mapped_df.reset_state()\n",
    "    for _ in iter(mapped_df):\n",
    "        pbar.update()\n",
    "    for d_path in dst_path_l:\n",
    "        exe.run_command(\n",
    "            [\"cp\", \"-r\", \"{:}/spacetime_camera\".format(rt_path), \"{:}/spacetime_camera\".format(d_path)])\n",
    "        exe.run_command(\n",
    "            [\"cp\", \"{:}/new_meta.mdb\".format(rt_path), \"{:}/new_meta.mdb\".format(d_path)])\n",
    "    pbar.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
